{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd \"~/Projects/Segmentation/TreeSeg\"\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import nvdiffrast.torch as dr\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import cv2\n",
    "from rich.console import Console\n",
    "from rich.tree import Tree\n",
    "import torch_geometric as pyg\n",
    "\n",
    "import tree_segmentation as ts\n",
    "import tree_segmentation.extension as ext\n",
    "from tree_segmentation.extension import ops_3d, Mesh, utils\n",
    "from semantic_sam import SemanticSAM, semantic_sam_l, semantic_sam_t\n",
    "from segment_anything import build_sam\n",
    "from tree_segmentation import  TreePredictor, TreeSegmentMetric, Tree2D, MaskData\n",
    "from tree_segmentation.util import show_masks, show_all_levels, get_hash_name\n",
    "from evaluation.batch_eval_PartNet import get_mesh_and_gt_tree, get_images\n",
    "import pycocotools.mask as mask_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "torch.set_grad_enabled(False)\n",
    "console = Console()\n",
    "device = torch.device(\"cuda\")\n",
    "# device = torch.device(\"cpu\")\n",
    "utils.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('/data5/SA-1B/')\n",
    "data_part_1 = data_root.joinpath(f\"{0:06d}\")\n",
    "images_paths = list(data_part_1.glob('*.jpg'))\n",
    "print(f\"There are {len(images_paths)} images\")\n",
    "print(len(list(data_part_1.glob('*.json'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations(json_path: Path):\n",
    "    masks = []\n",
    "    scores = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    annotations = data['annotations']\n",
    "    for ann in annotations:\n",
    "        scores.append(ann['predicted_iou'])\n",
    "        masks.append(mask_util.decode(ann['segmentation']))\n",
    "    scores = np.stack(scores)\n",
    "    masks = np.stack(masks)\n",
    "    tree2d = Tree2D(MaskData(masks=torch.from_numpy(masks), iou_preds=torch.from_numpy(scores)))\n",
    "    tree2d.update_tree()\n",
    "    return tree2d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = utils.load_image(images_paths[0])\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree2d = read_annotations(images_paths[0].with_suffix('.json'))\n",
    "tree2d.print_tree()\n",
    "show_all_levels(image, tree2d, alpha=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load SAM\n",
    "assert torch.cuda.is_available()\n",
    "# model = build_sam(Path('./weights/sam_vit_h_4b8939.pth').expanduser())\n",
    "model = semantic_sam_l(Path(\"./weights/swinl_only_sam_many2many.pth\").expanduser())\n",
    "# model = semantic_sam_t( Path(\"./weights/swint_only_sam_many2many.pth\").expanduser())\n",
    "model = model.eval().to(device)\n",
    "tree_seg = TreePredictor(model, box_nms_thresh=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "H, W, _ = image.shape\n",
    "scale = min(1024 / H, 1024 / W)\n",
    "image_resized = cv2.resize(image, (int(scale * W), int(scale * H)), interpolation=cv2.INTER_AREA)\n",
    "print(image_resized.shape)\n",
    "plt.imshow(image_resized)\n",
    "prediction = tree_seg.generate(image_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.print_tree()\n",
    "show_all_levels(image_resized, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_segmentation.metric import TreeSegmentMetric\n",
    "metric = TreeSegmentMetric(is_resize_2d_as_gt=True)\n",
    "metric.update(prediction.to(device), tree2d.to(device))\n",
    "for k, v in metric.summarize().items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_a = prediction.masks[142 - 1]\n",
    "mask_b = prediction.masks[150 - 1]\n",
    "print(mask_a.sum(), mask_b.sum())\n",
    "inter = (mask_a * mask_b).sum()\n",
    "print(inter)\n",
    "print(inter / (mask_a.sum() + mask_b.sum() - inter))\n",
    "show_masks(None, mask_a, mask_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric.calc_tree_structure_score(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutate Semantic-SAM-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose eval images\n",
    "part_idx = 110 # < 110\n",
    "num_eval = 10\n",
    "\n",
    "images_paths =sorted( list(data_root.joinpath(f\"{part_idx:06d}\").glob('*.jpg')))\n",
    "np.random.seed(42)\n",
    "eval_image_paths = np.random.choice(images_paths, num_eval)\n",
    "print(f\"Try To evaluate {len(eval_image_paths)} image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = semantic_sam_l(Path(\"./weights/swinl_only_sam_many2many.pth\").expanduser())\n",
    "# model = semantic_sam_t( Path(\"./weights/swint_only_sam_many2many.pth\").expanduser())\n",
    "model = model.eval().to(device)\n",
    "tree_seg = TreePredictor(model)\n",
    "# init metric\n",
    "metirc = TreeSegmentMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree_segmentation.metric import TreeSegmentMetric\n",
    "timer = utils.TimeEstimator(num_eval)\n",
    "time_avg = utils.TimeWatcher()\n",
    "timer.start()\n",
    "time_avg.start()\n",
    "for i, image_path in enumerate(eval_image_paths, 1):\n",
    "    image = utils.load_image(image_path)\n",
    "    H, W, _ = image.shape\n",
    "    scale = min(1024 / H, 1024 / W)\n",
    "    image = cv2.resize(image, (int(scale * W), int(scale * H)), interpolation=cv2.INTER_AREA)\n",
    "    time_avg.log('image')\n",
    "    gt = read_annotations(image_path.with_suffix('.json'))\n",
    "    time_avg.log('gt')\n",
    "    prediction = tree_seg.generate(image, device=device)\n",
    "    time_avg.log('tree2d')\n",
    "    metirc.update(prediction, gt.to(device), return_match=False)\n",
    "    time_avg.log('metric')\n",
    "    timer.step()\n",
    "    if i % 2 == 0:\n",
    "        print(f'Process [{i+1}/{num_eval}], time: {timer.progress}',\n",
    "              ', '.join(f'{k}: {utils.float2str(v)}' for k, v in metirc.summarize().items()))\n",
    "\n",
    "print('Complete Evalution')\n",
    "print('Time:', time_avg)\n",
    "for k, v in metirc.summarize().items():\n",
    "    print(f\"{k:5s}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
